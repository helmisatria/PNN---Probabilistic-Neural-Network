#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Feb 28 22:17:07 2018

@author: helmisatria - 1301154325
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import axes3d, Axes3D
from sklearn.cross_validation import train_test_split

dataSet = np.genfromtxt('data_train_PNN.txt', skip_header=1)

dataX = dataSet[:,0]
dataY = dataSet[:,1]
dataZ = dataSet[:,2]
dataClass = dataSet[:,3]

uniqueClass = list(set(dataClass))

def euclidean(data1, data2):
    decX = (data1[0]-data2[0])**2
    decY = (data1[1]-data2[1])**2
    decZ = (data1[2]-data2[2])**2
    return np.sqrt(decX + decY + decZ)

def separateCol(data, dataSet, col):
    separatedClass = []
    for i, Class in enumerate(data):
        classes = []
        for y, rowData in enumerate(dataSet):
            if (rowData[col] == Class):
                classes.append(rowData)
        separatedClass.append(classes)
    return separatedClass

def neighborDistance(separatedClass):
    dataDistances = []
    for i, aClass in enumerate(separatedClass):
        dataClassDistance = []
        for y, row in enumerate(aClass):
            distances = []
            for z, insideRow in enumerate(aClass):
                if (y != z):
                    euc = euclidean(row, insideRow)
                    distances.append(euc)
            tmp = np.append(row, min(distances))
            dataClassDistance.append(tmp)
        dataDistances.append(dataClassDistance)
    dataDistances = np.concatenate((dataDistances))
    return dataDistances

def sumCol(data, col):
    dataSumDistances = []
    for i, val in enumerate(data):
        # sum all item in an array in column = 1
        dataSumDistances.append(sum(row[col] for row in val))
    return dataSumDistances

def cariF(g, dataSumDistances, separatedDataTrain):
    dataF = []
    for i, val in enumerate(dataSumDistances):
        dataF.append(float(g * dataSumDistances[i])/len(separatedDataTrain[i]))
    return(dataF)

def cariG(test, dataTrain, dataF):
    dataG = []
    for y, rowTest in enumerate(test):
        for i, rowTrain in enumerate(dataTrain):
            typeClass = rowTrain[3]
            #print('typeClass ', typeClass)
            calc = np.exp(-1 * (((rowTest[0] - rowTrain[0])**2) + ((rowTest[1] - rowTrain[1]) ** 2) + ((rowTest[2] - rowTrain[2]) ** 2)) / 2 * (dataF[int(typeClass)]) ** 2)
            tmp = np.append(rowTrain, calc)
            dataG.append(tmp)
    return dataG

def ValidationTest(dataTest, resultTest, g):
    count = 0
    countDataTest = len(dataTest)
    for i, val in enumerate(dataTest):
        if (val[3] == resultTest[i]):
            count += 1
    return count/countDataTest, g

def main(dataTrain, dataTest, dataF):
    Prediction = []
    x = []
    for i, rowTest in enumerate(dataTest):
        dataG = cariG([rowTest], dataTrain, dataF)
        # 3 = Class. separateCol 3 = separate an array to many based on col 3 (class)
        separateG = separateCol(uniqueClass, dataG, 3)
        # 5 = G(x) (column) per row
        sumSeparateG = sumCol(separateG, 5)
        Prediction.append(sumSeparateG.index(max(sumSeparateG)))
        tmp = np.append(rowTest, sumSeparateG.index(max(sumSeparateG)))
        x.append(tmp)
    return Prediction, x
# =============================================================================
# Data Preparation
# =============================================================================
z1separatedClass = separateCol(uniqueClass, dataSet, 3)
z2dataDistances = neighborDistance(z1separatedClass)
# -----------------------------------------------------------------------------

# Split Data train
Data_train, Data_test = train_test_split(z2dataDistances, test_size = 0.2)

z3separatedDataTrainClasses = separateCol(uniqueClass, Data_train, 3)

z4dataTrainDistClass = np.array(Data_train)[:, (3, 4)]

z5separatedDataTrain = separateCol(uniqueClass, z4dataTrainDistClass, 0)

z6dataSumDistances = sumCol(z5separatedDataTrain, 1)

# =============================================================================
# Mulai butuh data tes set (sebelumnya belum butuh), 
# sebelumnya masih olah data train buat dapetin sum distance buat cari F
# =============================================================================

# =============================================================================
# Single (G) Validation
# =============================================================================
dataF = cariF(6, z6dataSumDistances, z5separatedDataTrain)

Prediction, x = main(Data_train, Data_test, dataF)

dataX = np.array(x)[:,0]
dataY = np.array(x)[:,1]
dataZ = np.array(x)[:,2]
dataClass = np.array(x)[:, 5]

try1 = plt.axes(projection='3d')
try1.scatter(dataX, dataY, dataZ, c=dataClass, cmap='viridis', linewidth=0.5)

#print(ValidationTest(Data_test, Prediction, 6))
# =============================================================================

# =============================================================================
# =============================================================================
# # Real Data Test Experiment
# =============================================================================
# =============================================================================

dataTest= np.genfromtxt('data_test_PNN.txt', skip_header=1)

dataX = np.array(dataTest)[:,0]
dataY = np.array(dataTest)[:,1]
dataZ = np.array(dataTest)[:,2]

ax = plt.axes(projection='3d')
ax.scatter(dataX, dataY, dataZ, cmap='viridis', linewidth=0.5)

x1separatedClass = separateCol(uniqueClass, dataSet, 3)
x2dataDistances = neighborDistance(z1separatedClass)

x3separatedDataTrainClasses = separateCol(uniqueClass, z2dataDistances, 3)

x4dataTrainDistClass = np.array(z2dataDistances)[:, (3, 4)]

x5separatedDataTrain = separateCol(uniqueClass, x4dataTrainDistClass, 0)

x6dataSumDistances = sumCol(x5separatedDataTrain, 1)